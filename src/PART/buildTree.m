function [obj, nodes, log_probs] = buildTree(list, area, N, para, mark, total_set, min_number_points_block, min_cut_length, height, rule, max_n_unique)
    %[obj, nodes, log_probs] = buildTree(list, area, N, para, mark, total_set, rho, height, rule, max_n_unique)
    %
    %For a given list of MCMC draws from multiple subsets (could be 
    %multiple or one, but must be merged in one matrix).
    %buildTree returns the correponding partition tree stored in "obj", the
    %flattened tree and the corresponding probability (for sampling)
    %stored in "p" and "prob" respectively. buildTree is an inner function
    %to be called by buildForest. Do not use buildTree directly as it lacks
    %certain normalizing component when combining multple subsets. Using 
    %buildForest instead (you can build a forest containing one single
    %tree as well)
    %
    %[obj, p, prob] = buildTree(list, area, N, para, mark, total_set, rho,
    %height, rule, max_n_unique) returns the partition tree that combines the product of
    %densities from subset posterior samples.
    %
    %Arguments:
    %
    %list: A sum(N) x d matrix containing "pooled" MCMC samples. d is the dimension
    %      and N is a vector containing the number of samples on different subsets. If there are
    %      multiple subsets, all points are merged in one matrix, but the data
    %      will be indexed by "mark" (define later) for reference to the original
    %      subsets
    %area: the total area for cutting. It is a d x 2 matrix, each row 
    %      corresonding to one dimension, the first column is the minimum
    %      boundary and the second column is the maximum boundary. The 
    %      default value is generated by the largest and smallest value at 
    %      each dimension x 1.1
    %N: number of posterior samples for each subset MCMC
    %para: the columns/dimensions that buildTree is to cut.
    %mark: Index of data point. It would cost too much to store data directly
    %      in "obj" and "p", we instead store their index within each node
    %      in a form of (i, j) where j is the index for the subset and i is
    %      the index of the data point in that subset. For example, (1, 2) 
    %      means the first point from the second subset
    %total_set: total number of subsets
    %min_number_points_block: # of samples inside a block >= min_number_points_block
    %min_cut_length: either a scalar or a vector of the same dim as the
    %parameters. min_cut_length(j) corresponds to the minimum length of the
    %block for dim j.
    %height: We write buildTree in a recursion way, so use height to indicate
    %     the depth of the tree when building
    %rule: A function handle that determines the optimal cut at each gate
    %      that takes the format of 
    %     [index, value] = rule(x, l, r), where value is the cutting location
    %max_n_unique: maximum number of unique samples allowed in a leaf node
    %
    %Outputs:
    %
    %obj: the partition tree that gives the (combined) density estimation
    %nodes: A flattened obj containing all (leaf) nodes -- they represent a blockwise constant estimated density
    %log_probs: the log-probability for each node/block in nodes
    %
    % (NOTE: node=leaf, gate="non-leaf nodes") 
    % gates are only relevant to tree building; all the subsequent sampling
    % and combining only use nodes
    %
    %See also:
    %buildForest, MultiStageMCMC, OneStageMCMC
    
    %Obtain the total sample and dimension.
    [n, d] = size(list);
    
    % parameter parsing
    if isscalar(min_cut_length) 
        min_cut_length = min_cut_length * ones(1,d);
    end

    % number of unique samples (using dim 1 would suffice due to continuous
    % variable)
%     n_unique = length(unique(list(:,1))); 
    
    %Specify the default area
    if isempty(area) && height == 0
        area = zeros(d,2);
        area(:,1) = min(list)'; %min-boundary
        area(:,2) = max(list)'; %max-boundary
        assert(all(area(:,2)>area(:,1)), 'not strictly bigger');
        
        %To enlarge the boundary by a factor of 1.001 so that no boundary issue
        for i = 1:d
            if area(d,1) > 0
                area(d,1) = area(d,1)/1.001;
            else
                area(d,1) = area(d,1)*1.001;
            end
            
            if area(d,2) > 0
                area(d, 2) = area(d, 2)*1.001;
            else
                area(d, 2) = area(d, 2)/1.001;
            end
        end
    end
    
    %Starting building nodes
     
    
    % decide if this should be a leaf/block vs. continue cutting
    to_be_leaf = true;
    dim_to_cut = nan;
    cutting_point = nan;
    if isempty(para) 
        to_be_leaf = true;
    else
       % only those dimensions with length > min_cut_length are passed via para
        candidate_dims = para;
        % randomly choose a dimension and fetch the cutting point
        % until either (1) resulting a valid split (non-left) or (2)
        % candidate dimensions become empty
        while ~isempty(candidate_dims)
            dim_index = randsample(length(candidate_dims), 1);
            dim_to_cut = candidate_dims(dim_index);
            % call: rule(x, l, r, M, subset_index)
            [~, cutting_point] = feval(rule, list(:,dim_to_cut)', area(dim_to_cut,1), area(dim_to_cut,2), total_set, mark(:,2));
            if (cutting_point - area(dim_to_cut,1) >= min_cut_length(dim_to_cut)) && (area(dim_to_cut, 2) - cutting_point >= min_cut_length(dim_to_cut))
                left = list(:,dim_to_cut)<cutting_point; %bool vector: points that go to the left child
                right = list(:,dim_to_cut)>cutting_point; %bool vector: points that go to the right child
                if sum(left) >= min_number_points_block && sum(right) >= min_number_points_block
%                 if min(histc(mark(left,2), 1:total_set)) >= min_number_points_block && min(histc(mark(right,2), 1:total_set)) >= min_number_points_block
                    % this is a valid cut
                    to_be_leaf = false;
                    break;
                end
            end
            % non-valid cut
            candidate_dims(dim_index) = [];
        end
    end
    
    l = area(:,2) - area(:,1); %finding lenght on each side of a block  
    %Check if it is a node (meets the termination condition)
    if to_be_leaf
        %Yes!! This is a leaf!
        %Check if the area condition is violated (non-zero area)
        assert(all(l>0));

        %create a new node for the leaf
        obj = treeNode;

        % compute the aggregated density and probability via proper normalization 
        %count numbers of points in different subsets.
        c = histc(mark(:,2), 1:total_set); 
        if total_set > 1 %if there are multiple subsets
            counts = c + 0.1;%this number is used to bound away from 0

            %compute unnormalized probability & density in logarithm
            % density = density_1 x density_2 x ...
            %         = n_1/N_1/(prod of l) x n_2/N_2/(prod of l) x ...
            % prob = density x (prod of l)
            % unnormalized probability by multiplying subset-wise density
            % and then multiply the area
            obj.log_prob = sum(log(counts)) - sum(log(N)) - (total_set - 1)*sum(log(l)); 
            % unnormalized density in log scale
            obj.log_density = obj.log_prob - sum(log(l)); 
        else
            % if there's only one subset & compute probability and density
            obj.log_prob = log(n) - log(N);
            obj.log_density = obj.log_prob - sum(log(l));
        end
        
        % FIXME: comment them out
        assert(isfinite(sum(log(l))));
        assert(isfinite(obj.log_prob) && isfinite(obj.log_density));
        
        % store information in the leaf node 
        obj.point = mark; %the index of the data points
        obj.area = area; % the area
        
        % a local Gaussian kernel -- a gaussian (instead of uniform) estimated by the points in
        % the block
        % multiplicated Laplacian approximation is adopted
        if size(mark, 1)==1
            % cannot estimate from single point
            obj.cov = nan;
            obj.mean = nan;
        elseif total_set==1 || ~all(c>d)
            % multiple points from one subset or too few samples each set, one Gaussian
            obj.cov = cov(list)/total_set;
            obj.mean = mean(list, 1);
        else
            % multiplicated Laplacian
            tmp = zeros(d);
            agg_Mu = zeros(1,d);
            for m=1:total_set
                tmp_cov = cov(list(mark(:,2)==m, :));
                tmp = tmp + inv(tmp_cov);
                agg_Mu  = agg_Mu +  mean(list(mark(:,2)==m,:),1) / tmp_cov;
            end
            obj.cov = inv(tmp);
            obj.mean = agg_Mu * obj.cov;
            % test positive semidefiniteness
            [~, chol_number] = chol(obj.cov);
            if chol_number~=0
                % the matrix is not positive definite
                % fall back to crude estimation with pooled samples
                obj.cov = cov(list)/total_set;
                obj.mean = mean(list, 1);
            end
        end

        % singleton return values
        nodes = {obj}; %Output the leaf for constructing flattened tree (sampler)
        log_probs = [obj.log_prob]; %Output the corresponding probability for each leaf
    else
        %No!! This is not yet a leaf, then this is a gate! We need
        %to partition the data and build the partition rule on this
        %gate.
        obj = treeNode; %create the gate
        % NOTE: randomness of the ensemble
        obj.dim = dim_to_cut; %random select a dimension for building partition rule
        if height == 0 && d == 1
            %For one dimensional case, in order to introduce
            %randomness in building different trees, we always do a
            %random cut at the first step
            obj.value = list(randsample(1:n,1),obj.dim);
            left = list(:,obj.dim)<obj.value; %bool vector: points that go to the left child
            right = list(:,obj.dim)>obj.value; %bool vector: points that go to the right child
        else
            %Otherwise, we call the function handle @rule to
            %determine the cutting point
            obj.value = cutting_point;
        end

        % split into left vs. right depending on obj.value
        % We save all information at the gate
        obj.area = area; %the whole area
        middle = find(list(:,obj.dim)==obj.value); %middle is important when MCMC chain got stuck somewhere
        % randomly split the middle into left and right with half & half prob
        tmp = rand(size(middle))>0.5;
        left(middle(tmp)) = true;
        right(middle(~tmp)) = true;
        assert(all(left+right==1), 'wrong split'); % FIXME: comment it out
        list1 = list(left,:);
        list2 = list(right,:);
        mark1 = mark(left,:); %indexes that go to left
        mark2 = mark(right,:); %indexes that go to right

        area1 = area; %the area of the left child
        area1(obj.dim,:) = [area(obj.dim,1), obj.value];
        assert(all(area1(:,2)>area1(:,1)));

        area2 = area; %the area of the right child
        area2(obj.dim,:) = [obj.value, area(obj.dim,2)];
        assert(all(area2(:,2)>area2(:,1)));

        %We then recursively build the left sub-tree and right
        %sub-tree by calling the same buildTree function with
        %corresponding information
        
        % the candidate dimensions for next cutting are restricted to those wider than min_cutting_length
        para_1 = para(area1(para,2)-area1(para,1)>min_cut_length(para)');
        para_2 = para(area2(para,2)-area2(para,1)>min_cut_length(para)');

        %Build the left sub-tree
        [leftNode, nodes_left, log_probs_left] = buildTree(list1, area1, N, para_1, mark1, total_set, ...
            min_number_points_block, min_cut_length, height+1, rule, max_n_unique);

        %Build the right sub-tree
        [rightNode, nodes_right, log_probs_right] = buildTree(list2, area2, N, para_2, mark2, total_set, ...
            min_number_points_block, min_cut_length, height+1, rule, max_n_unique);

        %Connect the current gate to its left and right children
        obj.left = leftNode;
        obj.right = rightNode;

        %Augment the information for the flattened tree (sampler)
        nodes = [nodes_left, nodes_right]; % collecting the leaf nodes
        log_probs = [log_probs_left, log_probs_right];
    end
end